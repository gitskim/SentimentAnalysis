{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frOgc_DWOEbf",
        "colab_type": "text"
      },
      "source": [
        "# Data From IMDb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mtATdKyOJJP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "de032b09-324e-4dea-a4c6-0d576663741a"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/sentiment-rnn/data/labels.txt\n",
        "!wget https://github.com/udacity/deep-learning-v2-pytorch/raw/master/sentiment-rnn/data/reviews.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-01 22:50:13--  https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/sentiment-rnn/data/labels.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 225000 (220K) [text/plain]\n",
            "Saving to: ‘labels.txt’\n",
            "\n",
            "labels.txt          100%[===================>] 219.73K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-09-01 22:50:14 (4.37 MB/s) - ‘labels.txt’ saved [225000/225000]\n",
            "\n",
            "--2019-09-01 22:50:15--  https://github.com/udacity/deep-learning-v2-pytorch/raw/master/sentiment-rnn/data/reviews.txt\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/sentiment-rnn/data/reviews.txt [following]\n",
            "--2019-09-01 22:50:16--  https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/sentiment-rnn/data/reviews.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33678267 (32M) [text/plain]\n",
            "Saving to: ‘reviews.txt’\n",
            "\n",
            "reviews.txt         100%[===================>]  32.12M   128MB/s    in 0.3s    \n",
            "\n",
            "2019-09-01 22:50:20 (128 MB/s) - ‘reviews.txt’ saved [33678267/33678267]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuzoxVrjWRQs",
        "colab_type": "text"
      },
      "source": [
        "## Load in and visualize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4Du2wNwTgFw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "95ba9801-14fb-4dbb-ee05-5196eba588a8"
      },
      "source": [
        "import numpy as np\n",
        "with open('reviews.txt', 'r') as f:\n",
        "  reviews = f.read()  \n",
        "  \n",
        "with open('labels.txt', 'r') as f:\n",
        "  labels = f.read()\n",
        "\n",
        "  \n",
        "print(reviews[:345])\n",
        "print(\"---\")\n",
        "print(labels[:10])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through th\n",
            "---\n",
            "positive\n",
            "n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNhHn3gwW-Ra",
        "colab_type": "text"
      },
      "source": [
        "# Data Pre-Processing\n",
        "\n",
        "Encoding each word with an integer clean-up of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9YH4WcqW3eB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f37a1407-7f44-490b-fb05-b850cc68433f"
      },
      "source": [
        "from string import punctuation\n",
        "print(punctuation)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7SWAcMmXQQN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "4ce4edd2-53fa-47df-d5e3-2a3e23b13a6e"
      },
      "source": [
        "# Removing punctuation\n",
        "reviews = reviews.lower()\n",
        "all_text = ''.join([char for char in reviews if char not in punctuation])\n",
        "\n",
        "# split by new lines and spaces\n",
        "reviews_split = all_text.split('\\n')\n",
        "\n",
        "# putting all text back together. new liner is replaced by a space.\n",
        "all_text = ' '.join(reviews_split)\n",
        "\n",
        "# splitting a string using a space as a delimiter\n",
        "words = all_text.split()\n",
        "print(words[:30])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bromwell', 'high', 'is', 'a', 'cartoon', 'comedy', 'it', 'ran', 'at', 'the', 'same', 'time', 'as', 'some', 'other', 'programs', 'about', 'school', 'life', 'such', 'as', 'teachers', 'my', 'years', 'in', 'the', 'teaching', 'profession', 'lead', 'me']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkQxhU6lZwJc",
        "colab_type": "text"
      },
      "source": [
        "## Encoding the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvg4cSf5ZKD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "counts = Counter(words)\n",
        "# counts looks like {'the': 336713, 'and': 164107, ...}\n",
        "\n",
        "# sorts each unique word by its frequency of occurrence.\n",
        "# dictionary.get('key'). If 'key' does not exist, it returns None\n",
        "vocab = sorted(counts, key=counts.get, reverse=True)\n",
        "\n",
        "# vocab looks like ['the', 'and', 'a', 'of', ...]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1Is46Q9d8gh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9fc9aaec-5a18-47a4-aaab-294e3e0d112e"
      },
      "source": [
        "v = ['a', 'b', 'c']\n",
        "r = {word: index for index, word in enumerate(v, 7)} \n",
        "print(r)\n",
        "\n",
        "c = Counter('hello')\n",
        "print(c[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'a': 7, 'b': 8, 'c': 9}\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3a3eG3Qbt23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "2a20c89f-3ed0-4323-92f1-64174d9dd595"
      },
      "source": [
        "# map the words to an integer starting from 1\n",
        "vocab_to_int = {word: index for index, word in enumerate(vocab, start=1)}\n",
        "reviews_ints = []\n",
        "\n",
        "''' \n",
        "reviews_ints has words from reviews_split mapped to ints.\n",
        "['hello word', 'hello hi world'] becomes\n",
        "[[1, 2], [1, 3, 2]]\n",
        "'''\n",
        "for review in reviews_split:\n",
        "  reviews_ints.append([vocab_to_int[word] for word in review.split()])\n",
        "  \n",
        "  \n",
        "print(reviews_ints[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[21025, 308, 6, 3, 1050, 207, 8, 2138, 32, 1, 171, 57, 15, 49, 81, 5785, 44, 382, 110, 140, 15, 5194, 60, 154, 9, 1, 4975, 5852, 475, 71, 5, 260, 12, 21025, 308, 13, 1978, 6, 74, 2395, 5, 613, 73, 6, 5194, 1, 24103, 5, 1983, 10166, 1, 5786, 1499, 36, 51, 66, 204, 145, 67, 1199, 5194, 19869, 1, 37442, 4, 1, 221, 883, 31, 2988, 71, 4, 1, 5787, 10, 686, 2, 67, 1499, 54, 10, 216, 1, 383, 9, 62, 3, 1406, 3686, 783, 5, 3483, 180, 1, 382, 10, 1212, 13583, 32, 308, 3, 349, 341, 2913, 10, 143, 127, 5, 7690, 30, 4, 129, 5194, 1406, 2326, 5, 21025, 308, 10, 528, 12, 109, 1448, 4, 60, 543, 102, 12, 21025, 308, 6, 227, 4146, 48, 3, 2211, 12, 8, 215, 23]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTCYbMQxiOl7",
        "colab_type": "text"
      },
      "source": [
        "## Encoding Labels\n",
        "\n",
        "1 = positive, 0 = negative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blHHHMeHiJgN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "97cf1eb4-dc2c-45c0-acbe-1f441c3da279"
      },
      "source": [
        "labels_split = labels.split('\\n')\n",
        "encoded_labels = np.array([1 if label == 'positive' else 0 for label in labels_split])\n",
        "print(encoded_labels.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25001,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpT28twhlDzt",
        "colab_type": "text"
      },
      "source": [
        "## Getting rid of zero-length reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef94nPwWit73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "fefe139b-e97e-468a-8393-65d5179d137d"
      },
      "source": [
        "# Outlier data\n",
        "review_lens = Counter([len(x) for x in reviews_ints])\n",
        "# review_lens is in the form of {length : frequency}\n",
        "print(review_lens)\n",
        "print(f'Zero-length reviews: {review_lens[0]}')\n",
        "print(f'Maximum review length: {max(review_lens)}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({132: 185, 130: 185, 135: 178, 129: 177, 125: 177, 128: 173, 137: 171, 133: 171, 138: 170, 136: 170, 131: 170, 124: 167, 126: 167, 127: 163, 139: 162, 134: 160, 140: 156, 119: 154, 148: 151, 121: 149, 143: 148, 122: 145, 142: 143, 144: 142, 152: 142, 118: 137, 120: 136, 123: 136, 141: 134, 159: 131, 145: 131, 146: 130, 154: 129, 158: 127, 153: 126, 162: 126, 151: 126, 149: 125, 150: 124, 156: 124, 117: 123, 155: 122, 115: 122, 169: 120, 147: 120, 165: 119, 160: 116, 164: 115, 161: 113, 114: 110, 168: 109, 157: 108, 166: 107, 167: 106, 170: 102, 175: 102, 172: 102, 182: 100, 179: 98, 174: 97, 176: 96, 177: 94, 116: 94, 171: 94, 191: 94, 173: 94, 112: 93, 163: 93, 180: 92, 187: 91, 186: 90, 195: 90, 183: 89, 109: 87, 185: 86, 107: 84, 188: 83, 184: 82, 199: 82, 201: 82, 110: 80, 190: 80, 113: 80, 111: 79, 178: 78, 194: 77, 198: 76, 181: 75, 209: 73, 189: 73, 203: 73, 106: 72, 207: 72, 193: 71, 192: 71, 202: 71, 196: 69, 212: 69, 205: 69, 215: 69, 217: 69, 213: 69, 108: 68, 226: 66, 105: 65, 222: 65, 206: 65, 210: 64, 208: 64, 197: 63, 200: 63, 240: 63, 233: 62, 256: 62, 204: 62, 96: 60, 244: 60, 228: 60, 99: 60, 232: 60, 78: 59, 211: 59, 238: 58, 225: 58, 221: 57, 220: 57, 236: 57, 214: 57, 56: 56, 63: 56, 219: 55, 278: 55, 84: 55, 59: 55, 104: 54, 68: 54, 249: 53, 230: 53, 216: 53, 262: 52, 102: 52, 229: 52, 237: 52, 81: 52, 255: 52, 218: 52, 250: 51, 50: 51, 245: 51, 91: 51, 254: 50, 223: 50, 263: 50, 247: 50, 74: 50, 241: 50, 60: 50, 100: 49, 73: 49, 224: 49, 234: 49, 90: 49, 260: 49, 246: 48, 248: 48, 76: 48, 52: 48, 243: 47, 57: 47, 88: 47, 103: 47, 70: 47, 259: 47, 267: 47, 53: 47, 95: 47, 61: 47, 227: 46, 257: 46, 54: 45, 277: 45, 101: 45, 44: 45, 69: 45, 85: 45, 86: 44, 231: 44, 55: 44, 75: 44, 77: 44, 239: 44, 270: 44, 98: 43, 252: 43, 268: 43, 92: 43, 272: 43, 51: 43, 279: 43, 71: 43, 82: 43, 67: 42, 87: 42, 64: 42, 62: 42, 285: 42, 89: 41, 313: 41, 301: 41, 47: 41, 276: 41, 300: 41, 58: 41, 251: 41, 242: 40, 307: 40, 273: 40, 83: 40, 297: 39, 275: 39, 93: 39, 48: 39, 65: 39, 261: 39, 269: 39, 258: 38, 302: 38, 322: 38, 287: 38, 97: 37, 329: 37, 72: 37, 286: 37, 358: 37, 49: 37, 264: 37, 79: 37, 253: 36, 45: 36, 94: 36, 66: 36, 280: 35, 46: 35, 293: 35, 299: 34, 265: 34, 318: 34, 304: 34, 331: 33, 295: 33, 266: 33, 289: 33, 43: 32, 303: 32, 281: 32, 314: 32, 315: 31, 306: 31, 292: 31, 294: 31, 340: 31, 290: 30, 317: 30, 305: 30, 367: 30, 349: 30, 326: 30, 346: 29, 328: 29, 80: 29, 362: 29, 324: 29, 282: 29, 321: 29, 333: 28, 338: 28, 378: 28, 332: 28, 377: 28, 311: 28, 283: 27, 359: 27, 345: 27, 325: 27, 308: 27, 319: 27, 274: 27, 334: 27, 320: 27, 356: 27, 271: 27, 235: 27, 374: 27, 310: 27, 337: 26, 339: 26, 288: 26, 312: 26, 372: 26, 357: 26, 379: 26, 347: 25, 323: 25, 387: 25, 309: 25, 371: 25, 370: 25, 42: 25, 398: 24, 348: 24, 336: 24, 407: 24, 363: 24, 343: 24, 284: 24, 330: 23, 365: 23, 434: 23, 408: 23, 424: 23, 335: 23, 298: 23, 376: 23, 373: 23, 40: 23, 342: 22, 291: 22, 382: 22, 296: 22, 384: 22, 354: 22, 386: 22, 351: 22, 451: 21, 355: 21, 327: 21, 414: 21, 366: 21, 422: 21, 423: 20, 352: 20, 369: 20, 394: 20, 41: 20, 39: 20, 385: 19, 409: 19, 383: 19, 438: 19, 37: 19, 364: 19, 388: 19, 442: 19, 445: 19, 460: 18, 461: 18, 417: 18, 350: 18, 380: 18, 470: 18, 368: 18, 428: 18, 399: 18, 353: 17, 420: 17, 435: 17, 316: 17, 415: 17, 396: 17, 381: 17, 432: 17, 341: 17, 429: 17, 389: 17, 404: 17, 34: 17, 344: 17, 447: 16, 410: 16, 413: 16, 493: 16, 449: 16, 392: 16, 421: 16, 361: 16, 360: 16, 450: 16, 464: 16, 405: 16, 495: 16, 523: 15, 481: 15, 400: 15, 473: 15, 416: 15, 375: 15, 443: 15, 469: 15, 426: 15, 482: 15, 535: 15, 430: 15, 412: 14, 431: 14, 454: 14, 463: 14, 452: 14, 485: 14, 501: 14, 479: 14, 507: 14, 425: 14, 462: 14, 403: 14, 476: 14, 401: 13, 508: 13, 439: 13, 570: 13, 524: 13, 457: 13, 36: 13, 402: 13, 491: 13, 437: 13, 478: 13, 514: 13, 440: 13, 497: 13, 587: 12, 515: 12, 468: 12, 397: 12, 489: 12, 561: 12, 418: 12, 496: 12, 518: 12, 406: 12, 455: 12, 517: 12, 411: 12, 494: 12, 391: 12, 395: 12, 486: 12, 458: 12, 531: 12, 433: 12, 446: 12, 466: 12, 541: 11, 597: 11, 617: 11, 504: 11, 506: 11, 487: 11, 38: 11, 503: 11, 500: 11, 456: 11, 492: 11, 459: 11, 393: 11, 609: 11, 642: 11, 519: 10, 549: 10, 505: 10, 512: 10, 502: 10, 444: 10, 453: 10, 538: 10, 641: 10, 569: 10, 525: 10, 467: 10, 35: 10, 475: 10, 484: 10, 560: 10, 499: 10, 474: 10, 465: 10, 593: 9, 584: 9, 448: 9, 30: 9, 589: 9, 590: 9, 477: 9, 436: 9, 555: 9, 419: 9, 557: 9, 516: 9, 591: 9, 620: 9, 596: 9, 441: 9, 542: 9, 547: 9, 572: 9, 558: 9, 592: 9, 633: 9, 480: 9, 551: 8, 553: 8, 715: 8, 546: 8, 708: 8, 510: 8, 656: 8, 490: 8, 530: 8, 537: 8, 678: 8, 626: 8, 427: 8, 536: 8, 585: 8, 582: 8, 534: 8, 539: 8, 552: 8, 608: 8, 27: 8, 488: 8, 532: 8, 594: 8, 603: 8, 566: 7, 545: 7, 627: 7, 521: 7, 650: 7, 544: 7, 567: 7, 1023: 7, 606: 7, 575: 7, 783: 7, 472: 7, 556: 7, 755: 7, 809: 7, 725: 7, 577: 7, 509: 7, 564: 7, 605: 7, 636: 7, 390: 7, 713: 7, 619: 7, 563: 7, 554: 7, 583: 7, 602: 7, 635: 7, 665: 7, 682: 7, 483: 7, 543: 7, 737: 7, 562: 7, 550: 7, 527: 7, 528: 7, 533: 7, 677: 7, 733: 7, 568: 7, 529: 7, 885: 7, 697: 6, 675: 6, 598: 6, 614: 6, 1012: 6, 634: 6, 625: 6, 723: 6, 807: 6, 652: 6, 637: 6, 645: 6, 673: 6, 663: 6, 513: 6, 630: 6, 699: 6, 644: 6, 612: 6, 687: 6, 1018: 6, 711: 6, 691: 6, 659: 6, 604: 6, 607: 6, 624: 6, 29: 6, 622: 6, 785: 6, 522: 6, 32: 6, 724: 6, 471: 6, 618: 6, 540: 6, 581: 5, 736: 5, 676: 5, 649: 5, 751: 5, 763: 5, 964: 5, 688: 5, 31: 5, 1005: 5, 722: 5, 646: 5, 983: 5, 759: 5, 812: 5, 993: 5, 565: 5, 600: 5, 526: 5, 685: 5, 761: 5, 803: 5, 629: 5, 638: 5, 792: 5, 511: 5, 768: 5, 683: 5, 700: 5, 694: 5, 520: 5, 669: 5, 653: 5, 758: 5, 1020: 5, 753: 5, 940: 5, 571: 5, 578: 5, 611: 5, 781: 5, 623: 5, 661: 5, 747: 5, 860: 4, 991: 4, 729: 4, 658: 4, 965: 4, 664: 4, 874: 4, 680: 4, 800: 4, 22: 4, 573: 4, 832: 4, 872: 4, 924: 4, 586: 4, 816: 4, 735: 4, 795: 4, 706: 4, 726: 4, 833: 4, 889: 4, 654: 4, 794: 4, 712: 4, 579: 4, 1017: 4, 628: 4, 1010: 4, 548: 4, 643: 4, 33: 4, 931: 4, 748: 4, 716: 4, 719: 4, 702: 4, 934: 4, 616: 4, 821: 4, 788: 4, 1028: 4, 672: 4, 732: 4, 666: 4, 829: 4, 1029: 4, 887: 4, 771: 4, 811: 4, 776: 4, 632: 4, 601: 4, 679: 4, 741: 4, 933: 4, 610: 4, 648: 4, 865: 4, 574: 4, 786: 3, 20: 3, 994: 3, 1032: 3, 588: 3, 746: 3, 969: 3, 823: 3, 815: 3, 996: 3, 613: 3, 631: 3, 640: 3, 720: 3, 709: 3, 621: 3, 958: 3, 822: 3, 864: 3, 883: 3, 655: 3, 651: 3, 750: 3, 909: 3, 1026: 3, 595: 3, 784: 3, 703: 3, 857: 3, 767: 3, 667: 3, 858: 3, 796: 3, 701: 3, 749: 3, 826: 3, 24: 3, 1056: 3, 793: 3, 718: 3, 868: 3, 847: 3, 843: 3, 717: 3, 789: 3, 804: 3, 599: 3, 791: 3, 1019: 3, 932: 3, 615: 3, 689: 3, 670: 3, 705: 3, 966: 3, 819: 3, 774: 3, 692: 3, 1014: 3, 662: 3, 1007: 3, 770: 3, 639: 3, 854: 3, 894: 3, 845: 3, 752: 3, 690: 3, 998: 3, 866: 3, 914: 3, 817: 3, 801: 3, 859: 3, 814: 3, 968: 3, 1013: 3, 799: 3, 989: 3, 830: 3, 714: 3, 1037: 2, 754: 2, 901: 2, 808: 2, 835: 2, 820: 2, 766: 2, 873: 2, 850: 2, 982: 2, 764: 2, 1025: 2, 917: 2, 1061: 2, 26: 2, 728: 2, 28: 2, 963: 2, 721: 2, 855: 2, 841: 2, 827: 2, 935: 2, 671: 2, 559: 2, 988: 2, 867: 2, 1048: 2, 727: 2, 876: 2, 912: 2, 888: 2, 12: 2, 987: 2, 1046: 2, 846: 2, 838: 2, 1040: 2, 704: 2, 881: 2, 696: 2, 1042: 2, 25: 2, 948: 2, 844: 2, 825: 2, 16: 2, 15: 2, 1039: 2, 980: 2, 907: 2, 974: 2, 927: 2, 790: 2, 990: 2, 17: 2, 837: 2, 745: 2, 949: 2, 849: 2, 1011: 2, 1004: 2, 782: 2, 986: 2, 668: 2, 19: 2, 765: 2, 686: 2, 950: 2, 953: 2, 710: 2, 851: 2, 962: 2, 580: 2, 760: 2, 1034: 2, 695: 2, 498: 2, 1033: 2, 871: 2, 1001: 2, 902: 2, 842: 2, 992: 2, 1003: 2, 762: 2, 862: 2, 693: 2, 1049: 2, 999: 2, 1022: 2, 834: 2, 1015: 2, 698: 2, 911: 2, 1021: 2, 772: 2, 684: 2, 806: 2, 739: 2, 944: 2, 1006: 2, 647: 2, 863: 2, 957: 2, 918: 2, 916: 2, 942: 2, 742: 2, 576: 2, 731: 2, 779: 2, 880: 2, 978: 2, 926: 2, 1853: 1, 1316: 1, 937: 1, 1341: 1, 905: 1, 1230: 1, 10: 1, 870: 1, 954: 1, 893: 1, 895: 1, 1085: 1, 777: 1, 1008: 1, 2514: 1, 921: 1, 947: 1, 1045: 1, 1088: 1, 985: 1, 904: 1, 977: 1, 813: 1, 797: 1, 1098: 1, 1016: 1, 910: 1, 1091: 1, 1240: 1, 906: 1, 1009: 1, 818: 1, 929: 1, 1555: 1, 1587: 1, 1188: 1, 1036: 1, 11: 1, 831: 1, 744: 1, 1079: 1, 878: 1, 1646: 1, 13: 1, 886: 1, 848: 1, 1392: 1, 952: 1, 972: 1, 913: 1, 1030: 1, 920: 1, 967: 1, 869: 1, 773: 1, 674: 1, 1027: 1, 1773: 1, 1425: 1, 1867: 1, 778: 1, 1120: 1, 1124: 1, 903: 1, 769: 1, 946: 1, 1113: 1, 757: 1, 922: 1, 923: 1, 884: 1, 879: 1, 995: 1, 897: 1, 805: 1, 734: 1, 943: 1, 984: 1, 730: 1, 971: 1, 1053: 1, 1278: 1, 707: 1, 1568: 1, 802: 1, 840: 1, 743: 1, 1422: 1, 1186: 1, 1052: 1, 919: 1, 1077: 1, 877: 1, 852: 1, 856: 1, 660: 1, 891: 1, 853: 1, 1317: 1, 657: 1, 900: 1, 681: 1, 915: 1, 780: 1, 1050: 1, 970: 1, 740: 1, 14: 1, 1130: 1, 1360: 1, 1044: 1, 0: 1})\n",
            "Zero-length reviews: 1\n",
            "Maximum review length: 2514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlda0o1Wjs3a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "f2c5dd69-4407-4918-8b3b-7bd7f95e525f"
      },
      "source": [
        "# Remove any reviews/labels with zero length from the reviews_ints list\n",
        "removal_list = []\n",
        "for index, x in enumerate(reviews_ints):\n",
        "  if len(x) == 0:\n",
        "    print('here')\n",
        "    removal_list.append(index)\n",
        "\n",
        "print(removal_list)\n",
        "\n",
        "for index in removal_list:\n",
        "  del reviews_ints[index]\n",
        "  encoded_labels = np.delete(encoded_labels, index)\n",
        "  \n",
        "  \n",
        "  \n",
        "print(f'reviews_ints size: {len(reviews_ints)}, encoded_labels size: {len(encoded_labels)}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "here\n",
            "[25000]\n",
            "reviews_ints size: 25000, encoded_labels size: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KBs_RAaqJkT",
        "colab_type": "text"
      },
      "source": [
        "## Padding Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQuIPh0zlwWT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4b208982-3fca-45bb-b334-692a3834f618"
      },
      "source": [
        "# Given a = [11, 22, 33], a[-2:] is [22, 33]\n",
        "def pad_features(reviews_ints, seq_length):\n",
        "  features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
        "  for i, review in enumerate(reviews_ints):\n",
        "    # if the review's short, it will keep the zeros on the left and have the content on the right.\n",
        "    features[i, -len(review):] = np.array(review)[:seq_length]\n",
        "    \n",
        "  return features\n",
        "  \n",
        "\n",
        "seq_length = 200\n",
        "features = pad_features(reviews_ints, seq_length=seq_length)\n",
        "\n",
        "assert len(features) == len(reviews_ints)\n",
        "assert len(features[0] == seq_length)\n",
        "\n",
        "#print the first 2 rows of 5 values\n",
        "print(features[:2,:5])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 0 0]\n",
            " [0 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mEZrHdvuv6k",
        "colab_type": "text"
      },
      "source": [
        "## Data Loaders and Batching\n",
        "\n",
        "With train, validation, and test fractions equal to 0.8, 0.1, 0.1, respectively, the final, feature data shapes should look like:\n",
        "\n",
        "Train set:          (20000, 200) \n",
        "Validation set:     (2500, 200) \n",
        "Test set:           (2500, 200)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfeP5879tDKy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "1e7f2174-0ed6-40d0-b9ed-27cc965a7695"
      },
      "source": [
        "import torch \n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "split_frac = 0.8\n",
        "\n",
        "split_idx = int(len(features) * split_frac)\n",
        "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
        "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
        "\n",
        "test_idx = int(len(remaining_x) * 0.5)\n",
        "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
        "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
        "\n",
        "print(train_x.shape)\n",
        "print(val_x.shape)\n",
        "print(test_x.shape)\n",
        "\n",
        "print(train_y.shape)\n",
        "print(val_y.shape)\n",
        "print(test_y.shape)\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 50\n",
        "\n",
        "# make sure to SHUFFLE your data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 200)\n",
            "(2500, 200)\n",
            "(2500, 200)\n",
            "(20000,)\n",
            "(2500,)\n",
            "(2500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsSP9KJe8_ra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "b0ddb51a-cae2-4b2b-8f79-68a02884364f"
      },
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = dataiter.next()\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([50, 200])\n",
            "Sample input: \n",
            " tensor([[    0,     0,     0,  ...,   443,  2913,  3948],\n",
            "        [    0,     0,     0,  ...,  1197,  4821,   582],\n",
            "        [   11,     6,     3,  ...,     5,   168,    67],\n",
            "        ...,\n",
            "        [13771,  3600,   907,  ...,     3,  1098, 15299],\n",
            "        [   11,    18,     6,  ...,    73,   106,   620],\n",
            "        [    0,     0,     0,  ...,    46,    21,    80]])\n",
            "\n",
            "Sample label size:  torch.Size([50])\n",
            "Sample label: \n",
            " tensor([0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
            "        0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
            "        1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slaWlq5LA5Td",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Network in Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uihqTEXE9Dgv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "83de873e-cb8b-4dd2-afa5-4278ee71921b"
      },
      "source": [
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if (train_on_gpu):\n",
        "  print(\"training on gpu\")\n",
        "  \n",
        "else:\n",
        "  print(\"no gpu available\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training on gpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxx7y2TKBOx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "  \n",
        "  def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, \n",
        "               n_layers, drop_prob=0.5):\n",
        "    super(SentimentRNN, self).__init__()\n",
        "    \n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    \n",
        "    # embedding and LSTM layers\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
        "    \n",
        "    # dropout layer\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "    \n",
        "    # linear and sigmoid layers\n",
        "    self.fc = nn.Linear(hidden_dim, output_size)\n",
        "    self.sig = nn.Sigmoid()\n",
        "    \n",
        "    \n",
        "  def forward(self, x, hidden):\n",
        "    \n",
        "    batch_size = x.size(0)\n",
        "    \n",
        "    embeds = self.embedding(x)\n",
        "    lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    \n",
        "    # stack up lstm outputs\n",
        "    lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "    \n",
        "    # dropout and fully-connected layer\n",
        "    out = self.dropout(lstm_out)\n",
        "    out = self.fc(out)\n",
        "\n",
        "    # sigmoid function\n",
        "    sig_out = self.sig(out)\n",
        "\n",
        "    # reshape to be batch_size first\n",
        "    sig_out = sig_out.view(batch_size, -1)\n",
        "    sig_out = sig_out[:, -1] # get last batch of labels\n",
        "\n",
        "    # return last sigmoid output and hidden state\n",
        "    return sig_out, hidden\n",
        "  \n",
        "  \n",
        "  def init_hidden(self, batch_size):\n",
        "    weight = next(self.parameters()).data\n",
        "    \n",
        "    if (train_on_gpu):\n",
        "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "    else:\n",
        "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "\n",
        "    return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd2sVxSdTnp4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "5f4cba99-7486-4c31-db33-fdca2240469c"
      },
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(net)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(74073, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cougmGHTrS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcOzvn2SUKzH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "90d3ebef-4fca-48dd-9e44-fc4305a45e73"
      },
      "source": [
        "# training params\n",
        "\n",
        "epochs = 4 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
        "\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip=5 # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "\n",
        "net.train()\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        # get the output from the model\n",
        "        output, h = net(inputs, h)\n",
        "\n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "\n",
        "                # Creating new variables for the hidden state, otherwise\n",
        "                # we'd backprop through the entire training history\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                if(train_on_gpu):\n",
        "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "                output, val_h = net(inputs, val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/4... Step: 100... Loss: 0.736194... Val Loss: 0.660989\n",
            "Epoch: 1/4... Step: 200... Loss: 0.628286... Val Loss: 0.644830\n",
            "Epoch: 1/4... Step: 300... Loss: 0.599046... Val Loss: 0.575069\n",
            "Epoch: 1/4... Step: 400... Loss: 0.542037... Val Loss: 0.522899\n",
            "Epoch: 2/4... Step: 500... Loss: 0.420055... Val Loss: 0.570658\n",
            "Epoch: 2/4... Step: 600... Loss: 0.483966... Val Loss: 0.516295\n",
            "Epoch: 2/4... Step: 700... Loss: 0.561418... Val Loss: 0.490463\n",
            "Epoch: 2/4... Step: 800... Loss: 0.304755... Val Loss: 0.471010\n",
            "Epoch: 3/4... Step: 900... Loss: 0.441638... Val Loss: 0.587238\n",
            "Epoch: 3/4... Step: 1000... Loss: 0.261099... Val Loss: 0.503679\n",
            "Epoch: 3/4... Step: 1100... Loss: 0.381693... Val Loss: 0.449291\n",
            "Epoch: 3/4... Step: 1200... Loss: 0.407934... Val Loss: 0.478880\n",
            "Epoch: 4/4... Step: 1300... Loss: 0.275053... Val Loss: 0.509744\n",
            "Epoch: 4/4... Step: 1400... Loss: 0.227476... Val Loss: 0.511192\n",
            "Epoch: 4/4... Step: 1500... Loss: 0.162259... Val Loss: 0.519354\n",
            "Epoch: 4/4... Step: 1600... Loss: 0.254354... Val Loss: 0.500261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqyIxO3QUjbz",
        "colab_type": "text"
      },
      "source": [
        "# Testing the train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsgeTO04UPN3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "998f6a39-cd2f-4ce4-ee99-49de37817c47"
      },
      "source": [
        "# Get test data loss and accuracy\n",
        "\n",
        "test_losses = [] # track loss\n",
        "num_correct = 0\n",
        "\n",
        "# init hidden state\n",
        "h = net.init_hidden(batch_size)\n",
        "\n",
        "net.eval()\n",
        "# iterate over test data\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "    # Creating new variables for the hidden state, otherwise\n",
        "    # we'd backprop through the entire training history\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    # get predicted outputs\n",
        "    output, h = net(inputs, h)\n",
        "\n",
        "    # calculate loss\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "\n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
        "\n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "\n",
        "\n",
        "# -- stats! -- ##\n",
        "# avg test loss\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "# accuracy over all test data\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.496\n",
            "Test accuracy: 0.805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjxuUfH9UlIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}